{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rgb2gray\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mImageGenerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator, ImageAugmentation\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EdgeDetection, Enhancement, Morphology\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graycomatrix, graycoprops\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Preprocessing'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as im\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import math\n",
    "from skimage.color import rgb2gray\n",
    "from ImageGenerator import ImageDataGenerator, ImageAugmentation\n",
    "from Preprocessing import EdgeDetection, Enhancement, Morphology\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample(images, labels):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i in range(7):\n",
    "        plt.subplot(1, 7, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.xlabel(f'ID`  {labels[i]}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "images, labels = datagen.flow_from_directory(\n",
    "    directory = 'Finger Dataset',\n",
    "    target_size=(300, 300),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_classes = np.unique(labels, return_counts=True)\n",
    "plt.bar(count_classes[0], count_classes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sample(images=images, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(images, labels, n_samples):\n",
    "    unique_labels = np.unique(labels)\n",
    "    downsampled_images = []\n",
    "    downsampled_labels = []\n",
    "    for label in unique_labels:\n",
    "        indices = np.where(labels == label)[0]\n",
    "        selected_indices = np.random.choice(indices, n_samples, replace=True)\n",
    "        downsampled_images.extend(images[selected_indices])\n",
    "        downsampled_labels.extend(labels[selected_indices])\n",
    "\n",
    "        return np.array(downsampled_images), np.array(downsampled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = downsample(images, labels, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_classes = np.unique(labels, return_counts=True)\n",
    "plt.bar(count_classes[0], count_classes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sample(images=images, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentator = ImageAugmentation(\n",
    "    rotation_range=40,\n",
    "    height_shift_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.1,\n",
    ")\n",
    "\n",
    "images, lables = augmentator.flow(images, labels, num_augmentation=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in range(7):\n",
    "    plt.subplot(1, 7, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.xlabel('Original Image' if i == 0 else f\"Augmented Image {i}\")\n",
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skin_masking(images):\n",
    "    skin_images = []\n",
    "    for image in images:\n",
    "        R_Frame = image[:, :, 0]\n",
    "        G_Frame = image[:, :, 1]\n",
    "        B_Frame = image[:, :, 2]\n",
    "        BRG_Max = np.maximum.reduce([B_Frame, G_Frame, R_Frame])\n",
    "        BRG_Min = np.minimum.reduce([B_Frame, G_Frame, R_Frame])\n",
    "        Rule_1 = np.logical_and.reduce([R_Frame > 50, G_Frame > 40, B_Frame > 20, BRG_Max - BRG_Min > 13, abs(R_Frame - G_Frame) > 10, R_Frame > G_Frame, R_Frame > B_Frame])\n",
    "        Rule_2 = np.logical_and.reduce([R_Frame > 220, G_Frame > 210, B_Frame > 170, abs(R_Frame - G_Frame) <= 15, R_Frame > B_Frame, G_Frame > B_Frame])\n",
    "        mask = mask.astype(np.uint8) * 255\n",
    "        skin = cv2.bitwise_and(image, image, mask = mask)\n",
    "        skin_images.append(skin)\n",
    "    return np.array(skin_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_images = skin_masking(images)\n",
    "display_sample(images=skin_images, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gray Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_images = [cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) for image in skin_images]\n",
    "print(gray_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sample(images=gray_images, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphology = Morphology(kernel=np.ones((3,3), np.uint8), num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mask = morphology.binary(images=gray_images, binary_threshold=1)\n",
    "opening_mask = morphology.opening(images=binary_mask)\n",
    "\n",
    "display_sample(images=opening_mask, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(images, masks):\n",
    "    masked_images = []\n",
    "    for image, mask in zip(images, masks):\n",
    "        mask = mask.astype(np.uint8) * 255\n",
    "        masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "        masked_images.append(masked_image)\n",
    "    return masked_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening_images = apply_mask(gray_images, opening_mask)\n",
    "display_sample(images=opening_images, labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enchancer = Enhancement(num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_images = enchancer.blur_images(blur_type='median', images=opening_images, kernel_size=3)\n",
    "display_sample(images=enhanced_images, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image, size):\n",
    "    height, width = image.shape[:2]\n",
    "    new_height, new_width = size\n",
    "    y_new, x_new = np.indices((new_height, new_width))\n",
    "    y_new, x_new = (y_new * height // new_height).astype(int), (x_new * width // new_width).astype(int)\n",
    "    image_resized = image[y_new, x_new]\n",
    "    return image_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(images):\n",
    "    results = []\n",
    "    for image in images:\n",
    "        binary_image = np.where(image > 87,  255, 0).astype(np.uint8)\n",
    "        rows, cols = np.nonzero(binary_image)\n",
    "        min_row, min_col = np.min(rows), np.min(cols)\n",
    "        max_row, max_col = np.max(rows), np.max(cols)\n",
    "        cropped_image = image[min_row:max_row+1, min_col:max_col+1]\n",
    "        resized_image = resize(cropped_image, (75, 75))\n",
    "        results.append(resized_image)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours_images = find_contours(enhanced_images)\n",
    "display_sample(images=contours_images, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = {\n",
    "    'finger_1' : 0,\n",
    "    'finger_2' : 1,\n",
    "    'finger_3' : 2,\n",
    "    'finger_4' : 3,\n",
    "    'finger_5' : 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glcm_features(images, labels, distances=[5], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256, symmetric=True, normed=True):\n",
    "    features = ['contrast', 'dissimilarity', 'homogenity', 'energy', 'correlation']\n",
    "    angle_labels = ['0', '45', '90', '135']\n",
    "    df_data = pd.DataFrame()\n",
    "    for i, image in enumerate(images):\n",
    "        image = image.astype(int)\n",
    "        glcm = graycomatrix(image, distances, angles, levels, symmetric, normed)\n",
    "        for feature in features:\n",
    "            for angle, angle_label in zip(angles, angle_labels):\n",
    "                feat_a = graycoprops(glcm, feature)[0, int(angle*4/np.pi)]\n",
    "                df_data.loc[i, f'{feature}_{angle_label}'] = feat_a\n",
    "        for angle, angle_label in zip(angles, angle_labels):\n",
    "            asm = np.sum(glcm[:,:,0,int(angle*4/np.pi)]**2)\n",
    "            entropy = -np.sum(glcm[:,:,0,int(angle*4/np.pi)]*np.log2(glcm[:,:,0,int(angle*4/np.pi)] + np.finfo(float).eps))\n",
    "            df_data.loc[i, f'asm_{angle_label}'] = asm\n",
    "            df_data.loc[i, f'entropy_{angle_label}'] = entropy\n",
    "        df_data.loc[i, 'label'] = dict_labels[labels[i]]\n",
    "    return df_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glcm = extract_glcm_features(contours_images, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glcm = pd.read_csv('glcm_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_glcm = df_glcm.corr()\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(corr_glcm, annot=True, cmap='coolwarm', cbar=False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=8)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df_glcm.drop('label', axis=1), df_glcm['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=25)\n",
    "x_pca = pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.2, random_state=42)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1, metric='cosine')\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "print('Accuracy: ', accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', C=30, gamma='auto')\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=500, class_weight='balanced', n_jobs=1, max_depth=50, min_samples_leaf=1, min_samples_split=2, bootstrap=False, criterion='gini')\n",
    "rfc.fit(x_train, y_train)\n",
    "y_pred = rfc.predict(x_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'KNN' : knn,\n",
    "    'SVM' : svm,\n",
    "    'RF' : rfc\n",
    "}\n",
    "\n",
    "df_eval = pd.DataFrame(columns=['Accuracy', 'Precision', 'Recall', 'F1 Score'], index=model_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in model_dict.items():\n",
    "    y_pred = model.predict(x_test)\n",
    "    df_eval.loc[model_name, 'Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    df_eval.loc[model_name, 'Precision'] = precision_score(y_test, y_pred, average='weighted')\n",
    "    df_eval.loc[model_name, 'Recall'] = recall_score(y_test, y_pred, average='weighted')\n",
    "    df_eval.loc[model_name, 'F1 Score'] = f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "for i, model_name in enumerate(model_dict.keys()):\n",
    "    y_pred = model_dict[model_name].predict(x_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, cmap='coolwarm', cbar=False, ax=ax[i])\n",
    "    ax[i].set_xlabel('Predicted')\n",
    "    ax[i].set_ylabel('True')\n",
    "    ax[i].set_title(model_name)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
